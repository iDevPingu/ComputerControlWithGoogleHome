{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from matplotlib import pyplot as plt\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.utils import pprint\n",
    "kkma = Kkma()\n",
    "from function import question_processing,tokenize_and_filter,tokenizer\n",
    "keras = tf.keras\n",
    "t = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 64)          5504      \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 80,003\n",
      "Trainable params: 80,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tempmodel = keras.models.load_model('entitytestmodel.h5')\n",
    "tempmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  word entity\n",
      "0  빨간색  color\n",
      "1  파랑색  color\n",
      "2  빨강색  color\n",
      "3  파란색  color\n",
      "4  주황색  color\n",
      "scanning was done                                        \n",
      "64 terms are recognized\n",
      "scanning was done                                        \n",
      "86 terms are recognized\n"
     ]
    }
   ],
   "source": [
    "intentdf = pd.read_csv('train_intent.csv',encoding=\"CP949\")\n",
    "entitydf = pd.read_csv('Entitytest.csv',encoding = \"CP949\")\n",
    "print(entitydf[0:5])\n",
    "intenttoken = tokenizer()\n",
    "intenttoken.fit(intentdf['question'].values)\n",
    "\n",
    "entitytoken = tokenizer()\n",
    "entitytoken.fit(entitydf['word'].values)\n",
    "\n",
    "intentmodel = keras.models.load_model('my_model.h5')\n",
    "entitymodel = keras.models.load_model('entitytestmodel.h5')\n",
    "\n",
    "def 형태소분석(text):\n",
    "    형태소 = kkma.pos(text)\n",
    "    명사 = []\n",
    "    for i in 형태소:\n",
    "        if i[1] == 'NNG':\n",
    "            명사.append(i[0])\n",
    "        else:\n",
    "            pass\n",
    "    return 명사\n",
    "\n",
    "def entity분석(명사):\n",
    "    inputdata = question_processing(명사,entitytoken)\n",
    "    prediction = list(np.argmax(entitymodel.predict(inputdata),axis=1))\n",
    "    print(명사)\n",
    "    print(prediction)\n",
    "    result = {}\n",
    "    for a,b in zip(명사,prediction):\n",
    "        if b == 0:\n",
    "            result[a] = 'color'\n",
    "        elif b == 1:\n",
    "            result[a] = 'thing'\n",
    "        elif b == 2:\n",
    "            result[a] = 'loc'\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = question_processing(['빨간색','휴지','파랑색','비','무지개색','오른쪽','노란색','유니폼','상자','옆','위'\n",
    "                                     ],entitytoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.4229478e-01, 3.1282444e-04, 5.7392407e-02],\n",
       "       [9.3867078e-05, 9.9887842e-01, 1.0277359e-03],\n",
       "       [9.4701344e-01, 2.4948525e-04, 5.2737065e-02],\n",
       "       [9.3867078e-05, 9.9887842e-01, 1.0277359e-03],\n",
       "       [9.6862912e-01, 3.1206716e-04, 3.1058801e-02],\n",
       "       [4.8841119e-02, 8.9883851e-03, 9.4217056e-01],\n",
       "       [9.4959462e-01, 3.2338305e-04, 5.0081894e-02],\n",
       "       [9.3867078e-05, 9.9887842e-01, 1.0277359e-03],\n",
       "       [4.1759838e-05, 9.9968314e-01, 2.7513146e-04],\n",
       "       [3.4237865e-02, 1.2231455e-02, 9.5353067e-01],\n",
       "       [2.2944862e-02, 1.5088378e-02, 9.6196675e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempmodel.predict(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 2 0 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "prediction = np.argmax(tempmodel.predict(input_sentence), axis=1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "keras = tf.keras\n",
    "t = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorizer import BaseVectorizer\n",
    "vectorizer = BaseVectorizer(t.morphs)\n",
    "tokenizer = BaseVectorizer(t.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Entitytest.csv',encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanning was done                                        \n",
      "105 terms are recognized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<vectorizer.BaseVectorizer at 0x25ea00dd188>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.fit(df['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.get_char2idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvoca = tokenizer.char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          8320      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 82,819\n",
      "Trainable params: 82,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tempmodel = keras.models.load_model('entitytestmodel.h5')\n",
    "tempmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_question_procession(words):\n",
    "    MAX_LENGTH = 10\n",
    "    inputs = [] \n",
    "    for word in words:\n",
    "        tempword = []\n",
    "        tempnum = []\n",
    "        for i in range(len(word)):\n",
    "            tempword.append(word[i])\n",
    "        for i in tempword:\n",
    "            try:\n",
    "                tempnum.append(wordvoca[i])\n",
    "            except:\n",
    "                pass\n",
    "        if len(tempnum) <= MAX_LENGTH:\n",
    "            inputs.append(tempnum)\n",
    "        else:\n",
    "            print(\"단어의 길이가 너무 길어요\")\n",
    "    padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    inputs, maxlen=MAX_LENGTH, padding='post', \n",
    "    value = tokenizer.char2idx['_PAD_']) # value = 0\n",
    "    return padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = word_question_procession(['빨간색','휴지','파랑색','비','무지개색','오른쪽','노란색','유니폼','상자','옆','위','뿡뿡색'\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99997258e-01, 2.36760138e-06, 3.79820023e-07],\n",
       "       [4.01552606e-05, 9.99946475e-01, 1.33432895e-05],\n",
       "       [9.99997973e-01, 1.85279464e-06, 1.44728048e-07],\n",
       "       [1.45368362e-02, 9.83871937e-01, 1.59128278e-03],\n",
       "       [7.20760524e-01, 2.78951228e-01, 2.88266368e-04],\n",
       "       [6.82854501e-04, 3.85420630e-04, 9.98931706e-01],\n",
       "       [9.99993563e-01, 6.26468636e-06, 1.59969190e-07],\n",
       "       [2.25275682e-04, 9.99717891e-01, 5.68391297e-05],\n",
       "       [7.61514675e-05, 9.99898911e-01, 2.49588320e-05],\n",
       "       [4.26918385e-04, 3.24093970e-04, 9.99248922e-01],\n",
       "       [4.10627166e-04, 3.02611763e-04, 9.99286830e-01],\n",
       "       [9.87252474e-01, 9.90190543e-03, 2.84563052e-03]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempmodel.predict(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = list(np.argmax(tempmodel.predict(input_sentence), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 2, 0, 1, 1, 2, 2, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
